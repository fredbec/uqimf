---
title: "IMF and Benchmark Forecasts"
header-includes:
    - \usepackage{lineno}
    - \linenumbers
    -  \newcommand{\beginsupplement}{\setcounter{table}{0}  \renewcommand{\thetable}{S\arabic{table}} \setcounter{figure}{0} \renewcommand{\thefigure}{S\arabic{figure}}}
output: 
  bookdown::pdf_document2:
    extra_dependencies: ["float"]
    keep_tex:  true
    toc: false
linestretch: 2 
geometry: "left=2cm,right=2cm,top=2cm,bottom=2cm"
bibliography:
  - references.bib
csl: vancouver.csl
---

```{r setup, include=FALSE}
library(data.table)
library(here)
library(ggplot2)
library(patchwork)
library(MetBrewer)
library(purrr)
library(lattice)
library(gt)
library(rlang)
library(tidyverse)
devtools::load_all()
knitr::opts_chunk$set(echo = TRUE)
.d <- `[`
```

# Extracting error quantiles

Consider a forecast that stems from a source $s$ for a specific target $k$ in a country $j$, for target year $t$ and with forecast horizon $h$:
\[
\hat{y}_{s,k,j,t,h}
\]
For example, this could be a forecast stemming from the International Monetary Fund World Economic Outlook ($s = IMF$) for real GDP growth ($k = gdpg$) in Canada ($j = Canada$) for the year $2022$ ($t=2022$). $h$ then indexes the forecast horizon, where we code:
\[
h = \left\{
\begin{array}{ll} 
      0, & \textrm{for forecasts made in October of the same year} \\
      0.5, & \textrm{for forecasts made in April of the same year} \\
      1, & \textrm{for forecasts made in October of the previous year} \\
      1.5, & \textrm{for forecasts made in April of the previous year} \\
\end{array}\right. 
\]
After the target year has completed, we obtain the realized value for the quantity of interest. For these, the WEO updates publishes biannual updates for two years, yielding $4$ versions of the realized value. In accordance with previous literature (\textit{cite Timmermann 2008}), we use the version that is published in October of the following year and thereby don't index the true value by its publishing date (\textit{rephrase}). We thus write the true value as
\[
\hat{y}_{k,j,t}
\]
Given the forecast and the realized value for the quantity of interest, we can calculate the respective forecast error as
\[
e^{d}_{s,k,j,t,h} = y_{k,j,t} - \hat{y}_{s,k,j,t,h}
\]

for the "directional" error method and as 
\[
e^{a}_{s,k,j,t,h} = \left|y_{k,j,t} - \hat{y}_{s,k,j,t,h}\right|
\]
for the "absolute" error method.

The objective is to extract quantiles from sets of errors $\mathcal{E}_{s,k,j,t,h}$ constructed of certain years, depending on the estimation method $m$, to be able to quantify the uncertainty inherent in the forecasts via central prediction intervals of level $\alpha = \{0.5, 0.8\}$. For the estimation method, we consider a "rolling window" method, an "expanding window" method, and a "leave-one-out" method. For the rolling window method ($m = rw$), the errors of the last nine years enter into the estimation. For the expanding window method ($m = ew$), all previous years are considered, leaving a nine year window up front for the first estimation. For the leave-one-out method, all years except the current target year enter the estimation set. The latter is of course equivalent to the expanding window method in a real time setting and is considered in the scope of this analysis as a mere check \textit{rephrase}.
As an example, the error set for the "directional" error method and the rolling window approach is
\[
\mathcal{E}^{d,rw}_{s,k,j,t,h} =  \left\{  e^{d}_{s,k,j,t^*,h} | t-9\leq t^* < t \right\}
\]
Insert reasoning to use the past $9$ errors.

To now obtain the lower $l$ and upper $u$ values for a central prediction interval of level $\alpha$, we take quantiles of these sets and add them to the current prediction:

For the directional method:
\[
l^{\alpha, d}_{t,h,v,l,j} = \hat{y}_{t, h, l, j} + q^{0.5 - \alpha/2 } \left(\mathcal{E}^{d, m}_{t,h,v,l,j}  \right)
\]
\[
u^{\alpha, d}_{t,h,v,l,j} = \hat{y}_{t, h, l, j} + q^{0.5 + \alpha/2 } \left(\mathcal{E}^{d, m}_{t,h,v,l,j}  \right)
\]

And for the absolute method: 

\[
 l^{\alpha, a}_{t,h,v,l,j} = \hat{y}_{t, h, l, j} -  q^{\alpha} \left(\mathcal{E}^{m, a}_{t,h,v,l,j}  \right)
\]
\[
u^{\alpha, a}_{t,h,v,l,j} = \hat{y}_{t, h, l, j} +  q^{\alpha} \left(\mathcal{E}^{m, a}_{t,h,v,l,j}  \right)
\]


Two different philosophies.

The absolute method will always yield symmetric central prediction intervals around the forecast value, while the directional method will in general yield asymmetric intervals. They thus result in different central intervals, unless the errors in $\mathcal{E}$ are perfectly symmetric around zero\footnote{Not totally correct, actually. For this to hold exactly, the error set would need to be augmented with one zero value.}. In fact, the directional method can yield central prediction intervals that do not even contain the forecast value, in cases where the $(0.5 - \alpha/2)$-quantile is positive or the $(0.5 + \alpha/2)$-quantile is negative.



```{r loaddata, echo = FALSE}
scores <- fread(here("scores", "ci_scores.csv"))

wis_scores <- fread(here("scores", "ci_scores_avgcnt.csv")) |>
  data.table::copy() |>
  .d(, .(model, error_method, method, target, horizon, interval_score, dispersion, underprediction, overprediction)) |>
  setnames("model", "source") 

crps_scores <- fread(here("scores", "sample_scores.csv")) 

#join score sets
all_scores <- 
  crps_scores[wis_scores, on = c("source", "error_method", "method", "target", "horizon")]|>
  .d(error_method == "absolute") |>
  .d(, error_method := NULL)

########

bvar_wis_scores <- fread(here("scores", "bvar_ci_scores_avgcnt.csv")) |>
  data.table::copy() |>
  .d(, .(model, target, horizon, interval_score, dispersion, underprediction, overprediction)) |>
  .d(,model := ifelse(model == "bvar_qu", "bvar_qu", "bvar_ciss")) |>
  setnames("model", "source") |>
  .d(,error_method := "directional") |>
  .d(,method := "rolling window") #change later


bvar_wis_scores <- rbind(bvar_wis_scores, bvar_wis_scores |> copy() |> .d(, error_method := "absolute"))

```




# Scores, by error method, Horizon and forecast source 

## Inflation

```{r overall_assessment_ew, fig.dim=c(12,12), echo = FALSE, warning = FALSE}

scores_cvgshort <- fread(here("scores", "ci_scores_avgcnt.csv")) |>
  setnames("model", "source", skip_absent = TRUE)


bvar_scores_cvgshort <- fread(here("scores", "bvar_ci_scores_avgcnt.csv")) |>
  setnames("model", "source", skip_absent = TRUE) |>
  .d(, source := ifelse(source == "bvar_qu", "bvar_qu", "bvar_ciss")) |>
  .d(, method := "rolling window") |>
  .d(, error_method := "absolute")


bvar_scores_cvgshort <- rbind(bvar_scores_cvgshort, bvar_scores_cvgshort |> copy() |> .d(, error_method := "directional"))


point_scores <- data.table::fread(here("scores", "pointfc_scores.csv")) 

wis_scores <- rbind(wis_scores, bvar_wis_scores)
scores_cvgshort <- rbind(scores_cvgshort, bvar_scores_cvgshort)

ovr_assessment_plot <- function(wis_scoredat, cvg_scoredat, point_scores, crps_scores, trgt, window_method){

  cvgscores <- cvg_scoredat |>
    .d(method == window_method) |>
    .d(target == trgt) |>
    .d(, target := NULL) |>
    .d(, method := NULL) 
  
  
  decomp_data <- wis_scoredat |>
    .d(method == window_method) |>
    .d(, method := NULL) 
  
  xmax <- max(decomp_data |> copy() |> .d(target == trgt) |> .d(, .(interval_score))) + 0.01
  
  point_scores <- point_scores |>
    .d(target == trgt) |>
    .d(, target := NULL) |>
    .d(, meanae := mean(ae), by = c("source", "horizon")) |>
    .d(, meansque := mean(sque), by = c("source", "horizon")) |>
    .d(, .(source, country, horizon, meanae, meansque)) |>
    unique()
  
  crps_scores_rw <- crps_scores |>
    .d(method == window_method) |>
    .d(target == trgt) |>
    .d(, target := NULL)
  
  crps_scores_loo <- crps_scores |>
    .d(method == "leave-one-out") |>
    .d(target == trgt) |>
    .d(, target := NULL)
  
  
  dir_wis_plot <- wis_plot_new(decomp_data |> .d(error_method  == "directional"), trgt, xmax = xmax, plot_name = "WIS - Directional Errors")
  abs_wis_plot <- wis_plot_new(decomp_data |> .d(error_method  == "absolute"), trgt, xmax = xmax, plot_name = "WIS - Absolute Errors")
  
  c50plot <- horizon_path_plot(cvgscores, "coverage_50", "CI Coverage - 50", facet = "error_method", title = "Central Interval Coverage - alpha = 50") +
    geom_hline(aes(yintercept = 0.5)) +
    scale_y_continuous(labels = paste0(seq(0, 100, by = 25), "%"),
                       breaks = seq(0,1, by = 0.25),
                       limits = c(0,1)) 
  
  c80plot <- horizon_path_plot(cvgscores, "coverage_80", "CI Coverage - 80", facet = "error_method", title = "Central Interval Coverage - alpha = 80") +
    geom_hline(aes(yintercept = 0.8)) +
    scale_y_continuous(labels = paste0(seq(0, 100, by = 25), "%"),
                       breaks = seq(0,1, by = 0.25),
                       limits = c(0,1)) 
  
  erow <-  ggplot() + theme_void()
  
  
  aeplot <- horizon_path_plot(point_scores |> .d(, error_method := "directional"), "meanae", "Absolute Error", title = "Point Forecast - Abs. Error")
  
  squeplot <- horizon_path_plot(point_scores |> .d(, error_method := "directional"), "meansque", "Squared Error", title = "Point Forecast - Squ. Error")
  
  crpsplot_rw <- horizon_path_plot(crps_scores_rw |>.d(, error_method := "directional"), "score", "CRPS by Sample", title = paste0("CRPS - ", window_method)) +
    scale_y_continuous(limits = c(0.07,1.05)) 
  
  
  crpsplot_loo <- horizon_path_plot(crps_scores_loo |>.d(, error_method := "directional"), "score", "CRPS by Sample", title = "CRPS - LOO") +
    scale_y_continuous(limits = c(0.07,1.05)) 
  
  
  
  ovr_plot <- 
    (dir_wis_plot | abs_wis_plot) /
    (plot_spacer()) /
    (c50plot | c80plot) /
    (plot_spacer()) /
    (squeplot | aeplot | crpsplot_rw | crpsplot_loo) +
    plot_layout(guides = "collect", 
                heights = c(0.2, 0.05, 0.2, 0.05, 0.2)) &
      plot_annotation(tag_levels = 'I')  &
      theme(legend.position = 'bottom', 
            legend.box="vertical", legend.margin=margin()) 


  
  return(ovr_plot)
}

ovr_assessment_plot(wis_scores, scores_cvgshort, point_scores, all_scores, trgt = "pcpi_pch", window_method = "rolling window")
   

```
\newpage
Some notes:
\begin{itemize}
\item Inflation: directional vs. absolute errors:
\begin{itemize}
\item difference small for IMF method, absolute slightly better, likely due to longer central intervals
\item AR and BVAR profit more from directional correction (upward bias)
\item for expanding window method, difference in coverage is smaller (-> structural breaks)

\end{itemize}
\item Inflation overall scores: IMF forecasts outperform others
\begin{itemize}
\item lower scores for point forecasts
\item lower WIS 
\item lower bias (compute directly?)
\end{itemize}


\item GDP Growth: more similar results for different sources
\begin{itemize}
\item lower scores at shorter horizons, more similar at larger horizons
\item IMF forecasts better only for absolute error method
\end{itemize}
\end{itemize}


\newpage

## GDP

```{r gdpovr_rw, echo = FALSE, warning = TRUE, fig.dim=c(12,12), warning = FALSE}

ovr_assessment_plot(wis_scores, scores_cvgshort, point_scores, all_scores, "ngdp_rpch", window_method = "rolling window")
```





# Expanding Window - Scores, by error method, Horizon and forecast source 

## Inflation
```{r infklovr_ew, echo = FALSE, warning = TRUE, fig.dim=c(12,12), warning = FALSE}

ovr_assessment_plot(wis_scores, scores_cvgshort, point_scores, all_scores, "ngdp_rpch", window_method = "expanding window")
```

\newpage



## GDP

```{r gdpovr, echo = FALSE, warning = TRUE, fig.dim=c(12,12), warning = FALSE}

ovr_assessment_plot(wis_scores, scores_cvgshort, point_scores, all_scores, "ngdp_rpch", window_method = "expanding window")
```



```{r cvgdat, include=FALSE, echo = FALSE}

scores <- fread(here("scores", "ci_scores.csv"))
scores_cvgshort <- fread(here("scores", "cvg_pooled.csv"))

cvg_rg <- c(50, 80)

cols <- paste0("coverage_", cvg_rg)

large_cvgdat <- scores |>
  setnames("model", "source") |>
  .d(, c("country", "horizon", "target", "error_method", "method", "source", cols), with = FALSE) |>
  melt(id.vars = c("country", "horizon", "target", "error_method", "method", "source"),
       variable.name = "pilvl",
       value.name = "coverage") |>
  .d(, pilvl := gsub("^.*?coverage_","",pilvl)) |>
  .d(, pilvl := as.numeric(pilvl)/100) |>
  .d(, idcol := paste0(horizon, country, method)) |>
  .d(, country := NULL) |>
  .d(, horizon := NULL)


cvgdat <- scores_cvgshort |>
  setnames("model", "source") |>
  .d(, c( "target", "error_method", "method", "source", cols), with = FALSE) |>
  melt(id.vars = c("target", "error_method", "method", "source"),
       variable.name = "pilvl",
       value.name = "coverage") |>
  .d(, pilvl := gsub("^.*?coverage_","",pilvl)) |>
  .d(, pilvl := as.numeric(pilvl)/100)


cvgdat_cpi <- cvgdat |>
  .d(target == "pcpi_pch")

cvgdat_gdp <- cvgdat |>
  .d(target == "ngdp_rpch")



#############block to merge with cvgdat symmetric

cvgdat_cpin <- data.table::fread(here("scores", "cvg_pooled_directionalsymmetric.csv")) |>
  setnames("model", "source") |>
  .d(, c( "target", "error_method", "method", "source", cols), with = FALSE) |>
  melt(id.vars = c("target", "error_method", "method", "source"),
       variable.name = "pilvl",
       value.name = "coverage") |>
  .d(, pilvl := gsub("^.*?coverage_","",pilvl)) |>
  .d(, pilvl := as.numeric(pilvl)/100) |>
  .d(target == "pcpi_pch") |>
  rbind(cvgdat_cpi)

cvgdat_cpi <- cvgdat_cpin


cvgdat_gdpn <- data.table::fread(here("scores", "cvg_pooled_directionalsymmetric.csv")) |>
  setnames("model", "source") |>
  .d(, c( "target", "error_method", "method", "source", cols), with = FALSE) |>
  melt(id.vars = c("target", "error_method", "method", "source"),
       variable.name = "pilvl",
       value.name = "coverage") |>
  .d(, pilvl := gsub("^.*?coverage_","",pilvl)) |>
  .d(, pilvl := as.numeric(pilvl)/100) |>
  .d(target == "ngdp_rpch") |>
  rbind(cvgdat_gdp)

cvgdat_gdp <- cvgdat_gdpn



plot_cpi <- ggplot() +
  geom_line(aes(x = pilvl,
                y = coverage,
                group = idcol),
            data = large_cvgdat |> .d(target == "pcpi_pch"),
            alpha = 0.4,
            color = "gray") +
  geom_point(aes(x = pilvl,
                 y = coverage,
                 color = method),
             data = cvgdat_cpi,
             size = 3) +
  geom_line(aes(x = pilvl,
                y = coverage,
                color = method),
            data = cvgdat_cpi,
            lwd = 1.25) +
  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1),
               color = "black",
               linetype = "dashed",
               data = cvgdat_cpi) +
  #scale_color_brewer(palette = "Set1") +
  facet_grid(source ~ error_method)+
  
  ggtitle("Inflation") +
  
  scale_color_met_d("Hokusai1") +
  
  ylab("Empirical Coverage Level (Central PI)") +
  xlab("Nominal Coverage (Central PI)") +
  theme_uqimf()


plot_gdp <- ggplot() +
  geom_line(aes(x = pilvl,
                y = coverage,
                group = idcol),
            data = large_cvgdat |> .d(target == "ngdp_rpch"),
            alpha = 0.4,
            color = "gray") +
  geom_point(aes(x = pilvl,
                 y = coverage,
                 color = method),
             data = cvgdat_gdp,
             size = 3) +
  geom_line(aes(x = pilvl,
                y = coverage,
                color = method),
            data = cvgdat_gdp,
            lwd = 1.25) +
  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1),
               color = "black",
               linetype = "dashed",
               data = cvgdat_gdp) +
  #scale_color_brewer(palette = "Set1") +
  facet_grid(source ~ error_method)+
  
  ggtitle("Real GDP Growth") + 
  
  scale_color_met_d("Hokusai1") +
  
  ylab("Empirical Coverage Level (Central PI)") +
  xlab("Nominal Coverage (Central PI)") +
  theme_uqimf()

```




# Coverage, by target, methods and source

```{r cvgplot, fig.dim = c(10, 12), echo = FALSE}

ovr_plot <- 
  (plot_gdp) /
  (plot_cpi) +
  plot_layout(guides = "collect", 
              heights = c(1, 1)) &
    plot_annotation(tag_levels = 'I')  &
    theme(legend.position = 'bottom', 
          legend.box="vertical", legend.margin=margin()) 

ovr_plot

```

\newpage
```{r, cpitable = FALSE, echo=FALSE}
#bring into long format
long_scores <- gather_scores(all_scores, "pcpi_pch")

scores_to_table(all_scores, "pcpi_pch")


```

## Inflation

```{r cpitileplot, echo = FALSE, warning=FALSE,fig.dim = c(10, 12)}

plots_is <- vector(mode = "list", length = 4)
plots_cr <- vector(mode = "list", length = 4)

hor_list <- as.list(1:4)

plots_is <- lapply(hor_list, function(i) tile_plot(long_scores, hor = (i-1)*0.5, "interval"))
plots_cr <- lapply(hor_list, function(i) tile_plot(long_scores, hor = (i-1)*0.5, "crps"))

ovr_plot <- 
  (plots_is[[1]] + plots_cr[[1]]) /
  (plots_is[[2]] + plots_cr[[2]]) /
  (plots_is[[3]] + plots_cr[[3]]) /
  (plots_is[[4]] + plots_cr[[4]]) +
  plot_layout(heights = c(1, 1,1,1)) &
    plot_annotation(tag_levels = 'I')  &
    theme(legend.position = 'right', 
          legend.box="vertical", legend.margin=margin()) 

ovr_plot

```




## GDP

```{r gdptable, echo = FALSE}

long_scores <- gather_scores(all_scores, "ngdp_rpch")
scores_to_table(all_scores, "ngdp_rpch")

```

```{r gdptileplot, echo = FALSE, warning=FALSE,fig.dim = c(10, 12)}

plots_is <- vector(mode = "list", length = 4)
plots_cr <- vector(mode = "list", length = 4)

hor_list <- as.list(1:4)

plots_is <- lapply(hor_list, function(i) tile_plot(long_scores, hor = (i-1)*0.5, "interval"))
plots_cr <- lapply(hor_list, function(i) tile_plot(long_scores, hor = (i-1)*0.5, "crps"))

ovr_plot <- 
  (plots_is[[1]] + plots_cr[[1]]) /
  (plots_is[[2]] + plots_cr[[2]]) /
  (plots_is[[3]] + plots_cr[[3]]) /
  (plots_is[[4]] + plots_cr[[4]]) +
  plot_layout(heights = c(1, 1,1,1)) &
    plot_annotation(tag_levels = 'I')  &
    theme(legend.position = 'right', 
          legend.box="vertical", legend.margin=margin()) 

ovr_plot

```


