---
title: "IMF and Benchmark Forecasts"
header-includes:
    - \usepackage{lineno}
    - \linenumbers
    -  \newcommand{\beginsupplement}{\setcounter{table}{0}  \renewcommand{\thetable}{S\arabic{table}} \setcounter{figure}{0} \renewcommand{\thefigure}{S\arabic{figure}}}
output: 
  bookdown::pdf_document2:
    extra_dependencies: ["float"]
    keep_tex:  true
    toc: false
linestretch: 2 
geometry: "left=2cm,right=2cm,top=2cm,bottom=2cm"
bibliography:
  - references.bib
csl: vancouver.csl
---

```{r setup, include=FALSE}
library(data.table)
library(here)
library(ggplot2)
library(patchwork)
library(MetBrewer)
library(purrr)
library(lattice)
library(gt)
library(rlang)
library(tidyverse)
devtools::load_all()
knitr::opts_chunk$set(echo = TRUE)
.d <- `[`
```

# Extracting error quantiles

Consider a forecast that stems from a source $s$ for a specific target $k$ in a country $j$, for target year $t$ and with forecast horizon $h$:
\[
\hat{y}_{s,k,j,t,h}
\]
For example, this could be a forecast stemming from the International Monetary Fund World Economic Outlook ($s = IMF$) for real GDP growth ($k = gdpg$) in Canada ($j = Canada$) for the year $2022$ ($t=2022$). $h$ then indexes the forecast horizon, where we code:
\[
h = \left\{
\begin{array}{ll} 
      0, & \textrm{for forecasts made in October of the same year} \\
      0.5, & \textrm{for forecasts made in April of the same year} \\
      1, & \textrm{for forecasts made in October of the previous year} \\
      1.5, & \textrm{for forecasts made in April of the previous year} \\
\end{array}\right. 
\]
After the target year has completed, we obtain the realized value for the quantity of interest. For these, the WEO updates publishes biannual updates for two years, yielding $4$ versions of the realized value. In accordance with previous literature (\textit{cite Timmermann 2008}), we use the version that is published in October of the following year and thereby don't index the true value by its publishing date (\textit{rephrase}). We thus write the true value as
\[
\hat{y}_{k,j,t}
\]
Given the forecast and the realized value for the quantity of interest, we can calculate the respective forecast error as
\[
e^{d}_{s,k,j,t,h} = y_{k,j,t} - \hat{y}_{s,k,j,t,h}
\]

for the "directional" error method and as 
\[
e^{a}_{s,k,j,t,h} = \left|y_{k,j,t} - \hat{y}_{s,k,j,t,h}\right|
\]
for the "absolute" error method.

The objective is to extract quantiles from sets of errors $\mathcal{E}_{s,k,j,t,h}$ constructed of certain years, depending on the estimation method $m$, to be able to quantify the uncertainty inherent in the forecasts via central prediction intervals of level $\alpha = \{0.5, 0.8\}$. For the estimation method, we consider a "rolling window" method, an "expanding window" method, and a "leave-one-out" method. For the rolling window method ($m = rw$), the errors of the last nine years enter into the estimation. For the expanding window method ($m = ew$), all previous years are considered, leaving a nine year window up front for the first estimation. For the leave-one-out method, all years except the current target year enter the estimation set. The latter is of course equivalent to the expanding window method in a real time setting and is considered in the scope of this analysis as a mere check \textit{rephrase}.
As an example, the error set for the "directional" error method and the rolling window approach is
\[
\mathcal{E}^{d,rw}_{s,k,j,t,h} =  \left\{  e^{d}_{s,k,j,t^*,h} | t-9\leq t^* < t \right\}
\]
Insert reasoning to use the past $9$ errors.

To now obtain the lower $l$ and upper $u$ values for a central prediction interval of level $\alpha$, we take quantiles of these sets and add them to the current prediction:

For the directional method:
\[
l^{\alpha, d}_{t,h,v,l,j} = \hat{y}_{t, h, l, j} + q^{0.5 - \alpha/2 } \left(\mathcal{E}^{d, m}_{t,h,v,l,j}  \right)
\]
\[
u^{\alpha, d}_{t,h,v,l,j} = \hat{y}_{t, h, l, j} + q^{0.5 + \alpha/2 } \left(\mathcal{E}^{d, m}_{t,h,v,l,j}  \right)
\]

And for the absolute method: 

\[
 l^{\alpha, a}_{t,h,v,l,j} = \hat{y}_{t, h, l, j} -  q^{\alpha} \left(\mathcal{E}^{m, a}_{t,h,v,l,j}  \right)
\]
\[
u^{\alpha, a}_{t,h,v,l,j} = \hat{y}_{t, h, l, j} +  q^{\alpha} \left(\mathcal{E}^{m, a}_{t,h,v,l,j}  \right)
\]


Two different philosophies.

The absolute method will always yield symmetric central prediction intervals around the forecast value, while the directional method will in general yield asymmetric intervals. They thus result in different central intervals, unless the errors in $\mathcal{E}$ are perfectly symmetric around zero\footnote{Not totally correct, actually. For this to hold exactly, the error set would need to be augmented with one zero value.}. In fact, the directional method can yield central prediction intervals that do not even contain the forecast value, in cases where the $(0.5 - \alpha/2)$-quantile is positive or the $(0.5 + \alpha/2)$-quantile is negative.

# A short note on error handling

In almost all 72 cases, absolute error handling gives lower scores than directional error handling. The only exception is the inflation series for the IMF forecasts and horizon 0, where the expanding window and rolling window method give \textit{slightly} lower scores for the directional methodology. 
We thus decide to focus on the absolute errors in this document. 


```{r loaddata, echo = FALSE}
scores <- fread(here("quantile_forecasts", "ci_scores.csv"))

wis_scores <- fread(here("quantile_forecasts", "ci_scores_avgcnt.csv")) |>
  data.table::copy() |>
  .d(, .(model, error_method, method, target, horizon, interval_score, dispersion, underprediction, overprediction)) |>
  setnames("model", "source") 

crps_scores <- fread(here("quantile_forecasts", "sample_scores.csv")) 

#join score sets
all_scores <- 
  crps_scores[wis_scores, on = c("source", "error_method", "method", "target", "horizon")]|>
  .d(error_method == "absolute") |>
  .d(, error_method := NULL)

```




# Scores, by estimation method, Horizon and forecast source 
```{r, cpitable = FALSE}
#bring into long format
long_scores <- gather_scores(all_scores, "pcpi_pch")

scores_to_table(all_scores, "pcpi_pch")


```

## Inflation

```{r cpitileplot, echo = FALSE, warning=FALSE,fig.dim = c(10, 12)}

plots_is <- vector(mode = "list", length = 4)
plots_cr <- vector(mode = "list", length = 4)

hor_list <- as.list(1:4)

plots_is <- lapply(hor_list, function(i) tile_plot(long_scores, hor = (i-1)*0.5, "interval"))
plots_cr <- lapply(hor_list, function(i) tile_plot(long_scores, hor = (i-1)*0.5, "crps"))

ovr_plot <- 
  (plots_is[[1]] + plots_cr[[1]]) /
  (plots_is[[2]] + plots_cr[[2]]) /
  (plots_is[[3]] + plots_cr[[3]]) /
  (plots_is[[4]] + plots_cr[[4]]) +
  plot_layout(heights = c(1, 1,1,1)) &
    plot_annotation(tag_levels = 'I')  &
    theme(legend.position = 'right', 
          legend.box="vertical", legend.margin=margin()) 

ovr_plot

```


## GDP

```{r gdptable, echo = FALSE}

long_scores <- gather_scores(all_scores, "ngdp_rpch")
scores_to_table(all_scores, "ngdp_rpch")

```

```{r gdptileplot, echo = FALSE, warning=FALSE,fig.dim = c(10, 12)}

plots_is <- vector(mode = "list", length = 4)
plots_cr <- vector(mode = "list", length = 4)

hor_list <- as.list(1:4)

plots_is <- lapply(hor_list, function(i) tile_plot(long_scores, hor = (i-1)*0.5, "interval"))
plots_cr <- lapply(hor_list, function(i) tile_plot(long_scores, hor = (i-1)*0.5, "crps"))

ovr_plot <- 
  (plots_is[[1]] + plots_cr[[1]]) /
  (plots_is[[2]] + plots_cr[[2]]) /
  (plots_is[[3]] + plots_cr[[3]]) /
  (plots_is[[4]] + plots_cr[[4]]) +
  plot_layout(heights = c(1, 1,1,1)) &
    plot_annotation(tag_levels = 'I')  &
    theme(legend.position = 'right', 
          legend.box="vertical", legend.margin=margin()) 

ovr_plot

```



```{r overall_assessment, fig.dim=c(12,12), echo = FALSE}

scores_cvgshort <- fread(here("quantile_forecasts", "ci_scores_avgcnt.csv")) |>
  setnames("model", "source", skip_absent = TRUE)

point_scores <- data.table::fread(here("quantile_forecasts", "pointfc_scores.csv")) 


ovr_assessment_plot <- function(wis_scoredat, cvg_scoredat, point_scores, crps_scores, trgt){

  cvgscores <- cvg_scoredat |>
    .d(method == "rolling window") |>
    .d(target == trgt) |>
    .d(, target := NULL) |>
    .d(, method := NULL) #|>
  
  
  decomp_data <- wis_scoredat |>
    .d(method == "rolling window") |>
    .d(target == trgt) |>
    .d(, target := NULL) |>
    .d(, method := NULL) #|>
  
  point_scores <- point_scores |>
    .d(target == trgt) |>
    .d(, target := NULL) |>
    .d(, meanae := mean(ae), by = c("source", "horizon")) |>
    .d(, meansque := mean(sque), by = c("source", "horizon")) |>
    .d(, .(source, country, horizon, meanae, meansque)) |>
    unique()
  
  crps_scores_rw <- crps_scores |>
    .d(method == "rolling window") |>
    .d(target == trgt) |>
    .d(, target := NULL)
  
  crps_scores_loo <- crps_scores |>
    .d(method == "leave-one-out") |>
    .d(target == trgt) |>
    .d(, target := NULL)
  
  
  xmax <- max(decomp_data$interval_score)
  
  decomp_data <- decomp_data |>
    data.table::melt(id.vars = c("source", "error_method", "horizon"),
                     value.name = "score",
                     variable.name = "type") |>
    .d(type != "interval_score") # filter out total score, only interested in decomposition
  
  
  
  #check arguments of function!
  wis_plot <- function(decompdat, error_m, maxval){
    
    if(error_m == "directional"){
      plot_name <- "Directional Errors"
    } else {
      plot_name <- "Absolute Errors"
    }
    
    
    plt <- ggplot(decomp_data |> .d(error_method == error_m),
                          aes(x = source, 
                              fill = source,
                              y = score,
                              alpha = type)) +
      geom_bar(position="stack", stat="identity") +
      facet_wrap(~ horizon,
                 labeller = as_labeller(plot_horizon_label_short(4)),
                 nrow = 1) +
      #geom_hline(yintercept = 1) +
      scale_alpha_discrete(range = c(0.35,1),
                           labels = c("Overprediction",
                                      "Underprediction",
                                      "Dispersion"),
                           name = "Components of the WIS") +
      scale_x_discrete(name = "",
                       breaks = c("IMF", "bvar", "ar"),
                       labels = c("IMF", "BVAR", "AR")) +
      scale_y_continuous(name = "WIS", limits = c(0, maxval)) +
      scale_fill_brewer(palette = "Set2", 
                        name = "Model Type")+
      xlab("") +
      #labs(fill = "Model Type") +
      theme_uqimf() %+replace%
      theme(axis.text.x = element_text(size = 8, angle = 90, hjust = .5, vjust = .5, face = "plain"),
            strip.text = element_text(size = 8)) +
      ggtitle(plot_name) +
      theme(#legend.title=element_blank(),
            legend.position = "none")

    return(plt)
  
  }
  
  horizon_path_plot <- function(score_data,
                                score_rule,
                                ylab = score_rule, 
                                facet = NULL){
    
    path_plot <- ggplot(score_data, 
           aes(x = horizon,
               y = get(score_rule), 
               color = source)) +
      scale_color_brewer(palette = "Set2") +
      geom_line() +
      geom_point() +
      ylab(ylab) +
      xlab("Forecast Horizon") +
      guides(fill = "none", colour = "none") +
      theme_uqimf() %+replace%
      theme(legend.title=element_blank(),
            legend.position = "none")
    
    if(!is.null(facet)){
      
      path_plot <- path_plot +
      facet_wrap(~ get(facet),
                 scales = "free") 
    }
    
    return(path_plot)
    
  }
  
  
    
  dir_wis_plot <- wis_plot(decomp_data, "directional", xmax)
  abs_wis_plot <- wis_plot(decomp_data, "absolute", xmax)
  
  c50plot <- horizon_path_plot(cvgscores, "coverage_50", "CI Coverage - 50", facet = "error_method") +
    geom_hline(aes(yintercept = 0.5)) +
    scale_y_continuous(labels = paste0(seq(0, 100, by = 25), "%"),
                       breaks = seq(0,1, by = 0.25),
                       limits = c(0,1)) 
  
  c80plot <- horizon_path_plot(cvgscores, "coverage_80", "CI Coverage - 80", facet = "error_method") +
    geom_hline(aes(yintercept = 0.8)) +
    scale_y_continuous(labels = paste0(seq(0, 100, by = 25), "%"),
                       breaks = seq(0,1, by = 0.25),
                       limits = c(0,1)) 
  
  erow <-  ggplot() + theme_void()
  
  
  aeplot <- horizon_path_plot(point_scores |> .d(, error_method := "directional"), "meanae", "Absolute Error")
  
  squeplot <- horizon_path_plot(point_scores |> .d(, error_method := "directional"), "meansque", "Squared Error")
  
  crpsplot_rw <- horizon_path_plot(crps_scores_rw |>.d(, error_method := "directional"), "score", "CRPS by Sample")
  
  crpsplot_loo <- horizon_path_plot(crps_scores_loo |>.d(, error_method := "directional"), "score", "CRPS by Sample")
  
  
  
  ovr_plot <- 
    (dir_wis_plot | abs_wis_plot) /
    (plot_spacer()) /
    (plot_annotation(title = "hey")) /
    (c50plot | c80plot) /
    (plot_spacer()) /
    (squeplot | aeplot | crpsplot_rw | crpsplot_loo) +
    plot_layout(guides = "collect", 
                heights = c(0.2, 0.05, 0.2, 0.05, 0.2)) &
      plot_annotation(tag_levels = 'I')  &
      theme(legend.position = 'bottom', 
            legend.box="vertical", legend.margin=margin()) 


  
  return(ovr_plot)
}

ovr_assessment_plot(wis_scores, scores_cvgshort, point_scores, all_scores, "pcpi_pch")
   

```



```{r cvgdat, include=FALSE, echo = FALSE}

scores <- fread(here("quantile_forecasts", "ci_scores.csv"))
scores_cvgshort <- fread(here("quantile_forecasts", "cvg_pooled.csv"))

cvg_rg <- c(50, 80)

cols <- paste0("coverage_", cvg_rg)

large_cvgdat <- scores |>
  setnames("model", "source") |>
  .d(, c("country", "horizon", "target", "error_method", "method", "source", cols), with = FALSE) |>
  melt(id.vars = c("country", "horizon", "target", "error_method", "method", "source"),
       variable.name = "pilvl",
       value.name = "coverage") |>
  .d(, pilvl := gsub("^.*?coverage_","",pilvl)) |>
  .d(, pilvl := as.numeric(pilvl)/100) |>
  .d(, idcol := paste0(horizon, country, method)) |>
  .d(, country := NULL) |>
  .d(, horizon := NULL)


cvgdat <- scores_cvgshort |>
  setnames("model", "source") |>
  .d(, c( "target", "error_method", "method", "source", cols), with = FALSE) |>
  melt(id.vars = c("target", "error_method", "method", "source"),
       variable.name = "pilvl",
       value.name = "coverage") |>
  .d(, pilvl := gsub("^.*?coverage_","",pilvl)) |>
  .d(, pilvl := as.numeric(pilvl)/100)


cvgdat_cpi <- cvgdat |>
  .d(target == "pcpi_pch")

cvgdat_gdp <- cvgdat |>
  .d(target == "ngdp_rpch")



#############block to merge with cvgdat symmetric

cvgdat_cpin <- data.table::fread(here("quantile_forecasts", "cvg_pooled_directionalsymmetric.csv")) |>
  setnames("model", "source") |>
  .d(, c( "target", "error_method", "method", "source", cols), with = FALSE) |>
  melt(id.vars = c("target", "error_method", "method", "source"),
       variable.name = "pilvl",
       value.name = "coverage") |>
  .d(, pilvl := gsub("^.*?coverage_","",pilvl)) |>
  .d(, pilvl := as.numeric(pilvl)/100) |>
  .d(target == "pcpi_pch") |>
  rbind(cvgdat_cpi)

cvgdat_cpi <- cvgdat_cpin


cvgdat_gdpn <- data.table::fread(here("quantile_forecasts", "cvg_pooled_directionalsymmetric.csv")) |>
  setnames("model", "source") |>
  .d(, c( "target", "error_method", "method", "source", cols), with = FALSE) |>
  melt(id.vars = c("target", "error_method", "method", "source"),
       variable.name = "pilvl",
       value.name = "coverage") |>
  .d(, pilvl := gsub("^.*?coverage_","",pilvl)) |>
  .d(, pilvl := as.numeric(pilvl)/100) |>
  .d(target == "ngdp_rpch") |>
  rbind(cvgdat_gdp)

cvgdat_gdp <- cvgdat_gdpn



plot_cpi <- ggplot() +
  geom_line(aes(x = pilvl,
                y = coverage,
                group = idcol),
            data = large_cvgdat |> .d(target == "pcpi_pch"),
            alpha = 0.4,
            color = "gray") +
  geom_point(aes(x = pilvl,
                 y = coverage,
                 color = method),
             data = cvgdat_cpi,
             size = 3) +
  geom_line(aes(x = pilvl,
                y = coverage,
                color = method),
            data = cvgdat_cpi,
            lwd = 1.25) +
  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1),
               color = "black",
               linetype = "dashed",
               data = cvgdat_cpi) +
  #scale_color_brewer(palette = "Set1") +
  facet_grid(source ~ error_method)+
  
  ggtitle("Inflation") +
  
  scale_color_met_d("Hokusai1") +
  
  ylab("Empirical Coverage Level (Central PI)") +
  xlab("Nominal Coverage (Central PI)") +
  theme_uqimf()


plot_gdp <- ggplot() +
  geom_line(aes(x = pilvl,
                y = coverage,
                group = idcol),
            data = large_cvgdat |> .d(target == "ngdp_rpch"),
            alpha = 0.4,
            color = "gray") +
  geom_point(aes(x = pilvl,
                 y = coverage,
                 color = method),
             data = cvgdat_gdp,
             size = 3) +
  geom_line(aes(x = pilvl,
                y = coverage,
                color = method),
            data = cvgdat_gdp,
            lwd = 1.25) +
  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1),
               color = "black",
               linetype = "dashed",
               data = cvgdat_gdp) +
  #scale_color_brewer(palette = "Set1") +
  facet_grid(source ~ error_method)+
  
  ggtitle("Real GDP Growth") + 
  
  scale_color_met_d("Hokusai1") +
  
  ylab("Empirical Coverage Level (Central PI)") +
  xlab("Nominal Coverage (Central PI)") +
  theme_uqimf()

```


# Coverage, by target, methods and source

```{r cvgplot, fig.dim = c(10, 12), echo = FALSE}

ovr_plot <- 
  (plot_gdp) /
  (plot_cpi) +
  plot_layout(guides = "collect", 
              heights = c(1, 1)) &
    plot_annotation(tag_levels = 'I')  &
    theme(legend.position = 'bottom', 
          legend.box="vertical", legend.margin=margin()) 

ovr_plot

```

